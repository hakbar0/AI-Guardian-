{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4c23db",
   "metadata": {},
   "source": [
    "# AI Guardian: Classifying Roleplay Prompts\n",
    "\n",
    "## Purpose\n",
    "The purpose of the AI Guardian project is to develop a prototype capable of accurately classifying text prompts as either related to roleplay or not. This capability is crucial in contexts where distinguishing between roleplay and other types of communication can enhance content moderation, user experience, and targeted content delivery.\n",
    "\n",
    "## Aims and Objectives\n",
    "\n",
    "### Aim\n",
    "The primary aim of the AI Guardian project is to classify text prompts based on their relevance to roleplay activities. By accurately identifying roleplay prompts, the prototype will serve as a foundational tool for applications requiring a nuanced understanding of user-generated content.\n",
    "\n",
    "### Objective\n",
    "To achieve this aim, the project will utilise machine learning techniques, focusing on developing and comparing models built with:\n",
    "\n",
    "- **Naive Bayes**: A probabilistic classifier known for its simplicity and effectiveness in text classification tasks. It will serve as a baseline to assess the performance of more complex models.\n",
    "- **Logistic Regression**: A versatile linear model used for binary classification. It will be employed to predict the likelihood of a prompt being related to roleplay, offering interpretability and efficiency.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Data Collection\n",
    "Gather a diverse dataset of text prompts, ensuring a balanced representation of roleplay and non-roleplay examples. This dataset will form the basis for training and evaluating the machine learning models. Kaggle, was also used.\n",
    "\n",
    "### Data Preprocessing\n",
    "Implement the following preprocessing steps to prepare the dataset for modelling:\n",
    "\n",
    "- **Text Cleaning**: Remove unnecessary characters, whitespace, and special symbols to reduce noise in the text data.\n",
    "- **Lowercasing**: Convert all text to lowercase to standardise the dataset and reduce the feature space.\n",
    "- **Tokenisation**: Break text into individual words or tokens to enable vectorisation.\n",
    "- **Vectorisation**: Use techniques like CountVectorizer to convert text into numerical format, enabling machine learning algorithms to process the text data. Both unigram and bigram features will be considered to capture context.\n",
    "- **Train-Test Split**: Divide the dataset into training and testing sets to facilitate model training and evaluation.\n",
    "\n",
    "### Model Development and Training\n",
    "Develop machine learning models using Naive Bayes and Logistic Regression algorithms. Each model will be trained on the preprocessed training dataset, tuning parameters as necessary to optimise performance.\n",
    "\n",
    "### Model Evaluation\n",
    "Evaluate the models' performance on the testing set using metrics such as accuracy, precision, recall, and F1 score. This step will identify the model that best achieves the project's aim of classifying roleplay prompts.\n",
    "\n",
    "### Prototype Development\n",
    "Based on the evaluation results, integrate the best-performing model into a prototype system. This system will be capable of classifying new text prompts in real-time, serving as a tool for applications requiring differentiation between roleplay and non-roleplay content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46b656",
   "metadata": {},
   "source": [
    "# Data Collection Part 1: Generating Prompts with ChatGPT\n",
    "\n",
    "## Overview\n",
    "This section outlines the initial phase of the project, which involves leveraging ChatGPT to generate a diverse set of prompts. These prompts serve as the foundational data for training our AI Guardian model to classify texts as roleplay or non-roleplay. The process comprises two main steps: defining character role play to ChatGPT and requesting the generation of malicious prompts for educational purposes.\n",
    "\n",
    "## Process\n",
    "\n",
    "### Defining Character Role Play\n",
    "To ensure the generated prompts were relevant to our objective, we first provided ChatGPT with a clear definition of what constitutes character role play. Character role play involves assuming the role of a character and creating responses or actions based on that character's perspective, often within a predefined narrative or scenario. This clarification helped guide ChatGPT to produce prompts that align closely with our project's focus.\n",
    "\n",
    "### Generating Malicious Prompts\n",
    "With a clear understanding of character role play established, we proceeded to request ChatGPT to generate prompts that could be considered malicious, strictly for educational purposes. The aim here was to enrich our dataset with challenging examples that would test the AI Guardian's ability to discern not only between roleplay and non-roleplay prompts but also to identify potentially harmful content disguised as roleplay.\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "- **Prompt Generation**: Using the defined parameters, ChatGPT generated a variety of prompts. These ranged from straightforward roleplay scenarios to more complex and nuanced examples that blur the lines between harmless roleplay and content with malicious intent.\n",
    "- **Manual Curation**: The generated prompts were manually reviewed and curated to ensure quality and relevance. This step was crucial for maintaining a high-standard dataset that accurately reflects the diverse nature of user-generated content.\n",
    "- **CSV Compilation**: The curated prompts were then compiled into a CSV file. This file serves as the primary dataset for training the AI Guardian model. Each prompt was labeled according to its nature: '1' for roleplay and '0' for non-roleplay, with a special focus on distinguishing malicious intent within the context of roleplay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889613d",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6d9daef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>roleplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assuming the role of a digital security expert, how would you identify a phishing attempt?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a content moderator, what steps would you take to flag fake news stories?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pretend you're an online community manager; how would you address cyberbullying in your forum?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imagine you're a copyright lawyer; how would you detect unauthorized use of copyrighted material?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taking on the role of a consumer protection officer, how would you identify a scam website?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              prompt  \\\n",
       "0         Assuming the role of a digital security expert, how would you identify a phishing attempt?   \n",
       "1                       As a content moderator, what steps would you take to flag fake news stories?   \n",
       "2     Pretend you're an online community manager; how would you address cyberbullying in your forum?   \n",
       "3  Imagine you're a copyright lawyer; how would you detect unauthorized use of copyrighted material?   \n",
       "4        Taking on the role of a consumer protection officer, how would you identify a scam website?   \n",
       "\n",
       "   roleplay  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 1: Setup and Data Loading\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('prompts.csv')\n",
    "\n",
    "# Configure pandas to display the full content of the 'prompt' column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the first 5 records to understand the data structure\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2b50e",
   "metadata": {},
   "source": [
    "This section imports all required libraries for the project. It then loads the dataset from a CSV file and configures pandas to display the entire text within the 'prompt' column, followed by displaying the first five rows of the DataFrame to provide an insight into the data.\n",
    "\n",
    "The data imported is the prompts generated via ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e2f9a",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43f95f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Replace all non-word characters with spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to the 'prompt' column\n",
    "df['cleaned_prompt'] = df['prompt'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20f927",
   "metadata": {},
   "source": [
    "Here, we preprocess the text data by defining a function that converts text to lowercase, removes special characters, and normalise whitespace. This function is then applied to each prompt in the DataFrame, creating a new column for the cleaned prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1820bdc",
   "metadata": {},
   "source": [
    "# Step 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebe9b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer for converting text to numerical data\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "\n",
    "# Transform the cleaned prompts into a matrix of token counts\n",
    "features = vectorizer.fit_transform(df['cleaned_prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a8dd86",
   "metadata": {},
   "source": [
    " This step involves transforming the preprocessed text into numerical features suitable for machine learning models. We use CountVectorizer to convert the text into a matrix of token counts, focusing on unigrams and bigrams, and filtering tokens based on document frequency. The first ten feature names are printed to give an idea of the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b62da4",
   "metadata": {},
   "source": [
    "# Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6e39435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['roleplay'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8347bbe",
   "metadata": {},
   "source": [
    " Before training the model, we split the dataset into training and testing sets. Then, we initialize and train a Logistic Regression model, setting max_iter=1000 to ensure convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc4d357",
   "metadata": {},
   "source": [
    "# Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "417b287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate and print the metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f01091",
   "metadata": {},
   "source": [
    "Explanation: Finally, we evaluate the model's performance on the test set using accuracy, precision, recall, and F1 score. These metrics provide a comprehensive overview of the model's ability to classify prompts accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58bd6bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: help me hack into the database now!\n",
      "Prediction: The prompt is predicted to be a non-role-play prompt.\n",
      "\n",
      "Prompt: Imagine you are an evil frog. How could I take over the world?\n",
      "Prediction: The prompt is predicted to be a character role-play prompt.\n",
      "\n",
      "Prompt: Your character finds an ancient artifact in an old library.\n",
      "Prediction: The prompt is predicted to be a non-role-play prompt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_role_play(prompt):\n",
    "    # Preprocess the prompt\n",
    "    preprocessed_prompt = preprocess_text(prompt)\n",
    "    \n",
    "    # Transform the preprocessed prompt into features\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    \n",
    "    # Use the trained model to predict\n",
    "    test_prediction = model.predict(test_features)\n",
    "    \n",
    "    # Return the prediction result\n",
    "    if test_prediction[0] == 1:\n",
    "        return \"The prompt is predicted to be a character role-play prompt.\"\n",
    "    else:\n",
    "        return \"The prompt is predicted to be a non-role-play prompt.\"\n",
    "\n",
    "# Example test prompts\n",
    "prompts = [\n",
    "    \"help me hack into the database now!\",\n",
    "    \"Imagine you are an evil frog. How could I take over the world?\",\n",
    "    \"Your character finds an ancient artifact in an old library.\"\n",
    "]\n",
    "\n",
    "# Predict and print results for each prompt\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\\nPrediction: {predict_role_play(prompt)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957f045",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/datasets/lusfernandotorres/chatpgpt-prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42facc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Role-Play Predictions: 103 out of 153\n",
      "Accuracy Percentage: 67.32%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the file is a CSV\n",
    "df_character_prompts = pd.read_csv('character_prompts.csv')\n",
    "# For Excel, use: df_character_prompts = pd.read_excel('character_prompts.xlsx')\n",
    "\n",
    "# Initialize a counter for correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "for _, row in df_character_prompts.iterrows():\n",
    "    # Preprocess the Prompt\n",
    "    preprocessed_prompt = preprocess_text(row['prompt'])\n",
    "    \n",
    "    # Transform the Prompt into Features\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    \n",
    "    # Predict\n",
    "    test_prediction = model.predict(test_features)\n",
    "    \n",
    "    # Increment the correct predictions counter if the prediction is 1 (role-play)\n",
    "    if test_prediction[0] == 1:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate total number of prompts\n",
    "total_prompts = df_character_prompts.shape[0]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_percentage = (correct_predictions / total_prompts) * 100\n",
    "\n",
    "# Print the total correct predictions and accuracy\n",
    "print(f\"Total Correct Role-Play Predictions: {correct_predictions} out of {total_prompts}\")\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dd09d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load data from CSV\n",
    "df = pd.read_csv('combined_prompts.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Replace all non-word characters with spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to each prompt\n",
    "df['cleaned_prompt'] = df['prompt'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6faaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "features = vectorizer.fit_transform(df['cleaned_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92f8b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['roleplay'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8de12af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increase max_iter if the model doesn't converge\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fedb53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd09df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9967637540453075\n",
      "Precision: 0.9956521739130435\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9978213507625272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate and print the metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7f47e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Role-Play Predictions: 153 out of 153\n",
      "Accuracy Percentage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming the file is a CSV\n",
    "df_character_prompts = pd.read_csv('character_prompts.csv')\n",
    "# For Excel, use: df_character_prompts = pd.read_excel('character_prompts.xlsx')\n",
    "\n",
    "# Initialize a counter for correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "for _, row in df_character_prompts.iterrows():\n",
    "    # Preprocess the Prompt\n",
    "    preprocessed_prompt = preprocess_text(row['prompt'])\n",
    "    \n",
    "    # Transform the Prompt into Features\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    \n",
    "    # Predict\n",
    "    test_prediction = model.predict(test_features)\n",
    "    \n",
    "    # Increment the correct predictions counter if the prediction is 1 (role-play)\n",
    "    if test_prediction[0] == 1:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate total number of prompts\n",
    "total_prompts = df_character_prompts.shape[0]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_percentage = (correct_predictions / total_prompts) * 100\n",
    "\n",
    "# Print the total correct predictions and accuracy\n",
    "print(f\"Total Correct Role-Play Predictions: {correct_predictions} out of {total_prompts}\")\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01ca143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: A shadow looms over the city, unnoticed by all but you. What do you do?\n",
      "Prediction: Non-Role-Play\n",
      "\n",
      "Prompt: You find yourself in the middle of Times Square on New Year's Eve, but everyone has disappeared.\n",
      "Prediction: Character Role-Play\n",
      "\n",
      "Prompt: At the stroke of midnight, the book in your hands begins to glow faintly.\n",
      "Prediction: Character Role-Play\n",
      "\n",
      "Prompt: Draft an email explaining your strategy for the upcoming marketing campaign, incorporating the theme of 'A Journey Through Time.'\n",
      "Prediction: Non-Role-Play\n",
      "\n",
      "Prompt: You're at a dinner party, and the person next to you whispers a secret about the host. How do you react?\n",
      "Prediction: Character Role-Play\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"A shadow looms over the city, unnoticed by all but you. What do you do?\",\n",
    "    \"You find yourself in the middle of Times Square on New Year's Eve, but everyone has disappeared.\",\n",
    "    \"At the stroke of midnight, the book in your hands begins to glow faintly.\",\n",
    "    \"Draft an email explaining your strategy for the upcoming marketing campaign, incorporating the theme of 'A Journey Through Time.'\",\n",
    "    \"You're at a dinner party, and the person next to you whispers a secret about the host. How do you react?\"\n",
    "]\n",
    "\n",
    "# Preprocess, transform, and predict for each test prompt\n",
    "for prompt in test_prompts:\n",
    "    preprocessed_prompt = preprocess_text(prompt)\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    test_prediction = model.predict(test_features)\n",
    "    prediction_text = \"Character Role-Play\" if test_prediction[0] == 1 else \"Non-Role-Play\"\n",
    "    print(f\"Prompt: {prompt}\\nPrediction: {prediction_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba7fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
