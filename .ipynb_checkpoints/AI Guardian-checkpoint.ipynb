{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2863f11f",
   "metadata": {},
   "source": [
    "# AI Guardian: Classifying Roleplay Prompts\n",
    "\n",
    "## Purpose\n",
    "The purpose of the AI Guardian project is to develop a prototype capable of accurately classifying text prompts as either related to roleplay or not. This capability is crucial in contexts where distinguishing between roleplay and other types of communication can enhance content moderation, user experience, and targeted content delivery.\n",
    "\n",
    "## Aims and Objectives\n",
    "\n",
    "### Aim\n",
    "The primary aim of the AI Guardian project is to classify text prompts based on their relevance to roleplay activities. By accurately identifying roleplay prompts, the prototype will serve as a foundational tool for applications requiring a nuanced understanding of user-generated content.\n",
    "\n",
    "### Objective\n",
    "To achieve this aim, the project will utilise machine learning techniques, focusing on developing and comparing models built with:\n",
    "\n",
    "- **Naive Bayes**: A probabilistic classifier known for its simplicity and effectiveness in text classification tasks. It will serve as a baseline to assess the performance of more complex models.\n",
    "- **Logistic Regression**: A versatile linear model used for binary classification. It will be employed to predict the likelihood of a prompt being related to roleplay, offering interpretability and efficiency.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Data Collection\n",
    "Gather a diverse dataset of text prompts, ensuring a balanced representation of roleplay and non-roleplay examples. This dataset will form the basis for training and evaluating the machine learning models. Kaggle, was also used.\n",
    "\n",
    "### Data Preprocessing\n",
    "Implement the following preprocessing steps to prepare the dataset for modelling:\n",
    "\n",
    "- **Text Cleaning**: Remove unnecessary characters, whitespace, and special symbols to reduce noise in the text data.\n",
    "- **Lowercasing**: Convert all text to lowercase to standardise the dataset and reduce the feature space.\n",
    "- **Tokenisation**: Break text into individual words or tokens to enable vectorisation.\n",
    "- **Vectorisation**: Use techniques like CountVectorizer to convert text into numerical format, enabling machine learning algorithms to process the text data. Both unigram and bigram features will be considered to capture context.\n",
    "- **Train-Test Split**: Divide the dataset into training and testing sets to facilitate model training and evaluation.\n",
    "\n",
    "### Model Development and Training\n",
    "Develop machine learning models using Naive Bayes and Logistic Regression algorithms. Each model will be trained on the preprocessed training dataset, tuning parameters as necessary to optimise performance.\n",
    "\n",
    "### Model Evaluation\n",
    "Evaluate the models' performance on the testing set using metrics such as accuracy, precision, recall, and F1 score. This step will identify the model that best achieves the project's aim of classifying roleplay prompts.\n",
    "\n",
    "### Prototype Development\n",
    "Based on the evaluation results, integrate the best-performing model into a prototype system. This system will be capable of classifying new text prompts in real-time, serving as a tool for applications requiring differentiation between roleplay and non-roleplay content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1f53b",
   "metadata": {},
   "source": [
    "# Data Collection Part 1: Generating Prompts with ChatGPT\n",
    "\n",
    "## Overview\n",
    "This section outlines the initial phase of the project, which involves leveraging ChatGPT to generate a diverse set of prompts. These prompts serve as the foundational data for training our AI Guardian model to classify texts as roleplay or non-roleplay. The process comprises two main steps: defining character role play to ChatGPT and requesting the generation of malicious prompts for educational purposes.\n",
    "\n",
    "## Process\n",
    "\n",
    "### Defining Character Role Play\n",
    "To ensure the generated prompts were relevant to our objective, we first provided ChatGPT with a clear definition of what constitutes character role play. Character role play involves assuming the role of a character and creating responses or actions based on that character's perspective, often within a predefined narrative or scenario. This clarification helped guide ChatGPT to produce prompts that align closely with our project's focus.\n",
    "\n",
    "### Generating Malicious Prompts\n",
    "With a clear understanding of character role play established, we proceeded to request ChatGPT to generate prompts that could be considered malicious, strictly for educational purposes. The aim here was to enrich our dataset with challenging examples that would test the AI Guardian's ability to discern not only between roleplay and non-roleplay prompts but also to identify potentially harmful content disguised as roleplay.\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "- **Prompt Generation**: Using the defined parameters, ChatGPT generated a variety of prompts. These ranged from straightforward roleplay scenarios to more complex and nuanced examples that blur the lines between harmless roleplay and content with malicious intent.\n",
    "- **Manual Curation**: The generated prompts were manually reviewed and curated to ensure quality and relevance. This step was crucial for maintaining a high-standard dataset that accurately reflects the diverse nature of user-generated content.\n",
    "- **CSV Compilation**: The curated prompts were then compiled into a CSV file. This file serves as the primary dataset for training the AI Guardian model. Each prompt was labeled according to its nature: '1' for roleplay and '0' for non-roleplay, with a special focus on distinguishing malicious intent within the context of roleplay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d03521",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e90988eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>roleplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assuming the role of a digital security expert, how would you identify a phishing attempt?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a content moderator, what steps would you take to flag fake news stories?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pretend you're an online community manager; how would you address cyberbullying in your forum?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imagine you're a copyright lawyer; how would you detect unauthorized use of copyrighted material?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taking on the role of a consumer protection officer, how would you identify a scam website?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              prompt  \\\n",
       "0         Assuming the role of a digital security expert, how would you identify a phishing attempt?   \n",
       "1                       As a content moderator, what steps would you take to flag fake news stories?   \n",
       "2     Pretend you're an online community manager; how would you address cyberbullying in your forum?   \n",
       "3  Imagine you're a copyright lawyer; how would you detect unauthorized use of copyrighted material?   \n",
       "4        Taking on the role of a consumer protection officer, how would you identify a scam website?   \n",
       "\n",
       "   roleplay  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 1: Setup and Data Loading\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('prompts.csv')\n",
    "\n",
    "# Configure pandas to display the full content of the 'prompt' column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the first 5 records to understand the data structure\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a0de2",
   "metadata": {},
   "source": [
    "This section imports all required libraries for the project. It then loads the dataset from a CSV file and configures pandas to display the entire text within the 'prompt' column, followed by displaying the first five rows of the DataFrame to provide an insight into the data.\n",
    "\n",
    "The data imported is the prompts generated via ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b91d4",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab44ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Replace all non-word characters with spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to the 'prompt' column\n",
    "df['cleaned_prompt'] = df['prompt'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa8f6d",
   "metadata": {},
   "source": [
    "## Why Text Preprocessing is Important:\n",
    "\n",
    "### Lowercasing (`text.lower()`):\n",
    "- **What it does:** Converts all characters in the text to lowercase.\n",
    "- **Why it's useful:** This standardises the text and ensures that the same words are recognised as identical, regardless of whether they appear at the start of a sentence or in lowercase in the middle. For example, \"Apple\" and \"apple\" are treated as the same word.\n",
    "- **Consequences of skipping:** Without lowercasing, words with the same spelling but different cases would be treated as distinct features, unnecessarily increasing the complexity of the feature space and potentially reducing model performance.\n",
    "\n",
    "### Removing Non-Word Characters (`re.sub(r'\\\\W', ' ', text)`):\n",
    "- **What it does:** Replaces characters that are not letters or numbers with spaces.\n",
    "- **Why it's useful:** This step cleans the text by removing punctuation, special symbols, and other characters that do not contribute to understanding the meaning of the text. It helps in focusing on the words themselves.\n",
    "- **Consequences of skipping:** Keeping these symbols could lead to a bloated feature set with many features that have little to no predictive power. For example, different forms of punctuation attached to words could lead to the same word being represented multiple times with different punctuations, diluting the model's ability to learn effectively.\n",
    "\n",
    "### Normalising Whitespace (`re.sub(r'\\\\s+', ' ', text)`):\n",
    "- **What it does:** Collapses multiple spaces into a single space.\n",
    "- **Why it's useful:** This ensures that spaces within the text are consistent, which is important for accurately separating words when tokenising the text later on. It helps to maintain a clean and consistent separation of words.\n",
    "- **Consequences of skipping:** Inconsistent whitespace can lead to issues in tokenisation, where the process of converting text into tokens (or words) could be incorrect. This can result in inaccurate feature extraction, impacting the model's learning and prediction capabilities.\n",
    "\n",
    "After applying these preprocessing steps, we add the cleaned text as a new column (`'cleaned_prompt'`) to the DataFrame. This ensures that our machine learning models are trained on clean, consistent text data, which is critical for achieving high accuracy and performance in text classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9bb34",
   "metadata": {},
   "source": [
    "# Step 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7630ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer for converting text to numerical data\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "\n",
    "# Transform the cleaned prompts into a matrix of token counts\n",
    "features = vectorizer.fit_transform(df['cleaned_prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99719d2f",
   "metadata": {},
   "source": [
    "## Understanding `CountVectorizer` Parameters:\n",
    "\n",
    "### `min_df=2`:\n",
    "- **What it does:** Specifies the minimum number of documents a word must appear in to be considered as a feature. Here, `min_df=2` means a word must appear in at least two documents to be included.\n",
    "- **Why it's useful:** This helps eliminate very rare words which might appear in only one document. Such words are often not useful for learning patterns across texts and can increase the dimensionality of the feature space without adding value.\n",
    "- **Consequence of skipping:** Without setting `min_df`, the feature matrix might include many rare terms, increasing the complexity of the model and potentially leading to overfitting.\n",
    "\n",
    "### `max_df=0.5`:\n",
    "- **What it does:** Specifies the maximum frequency within the documents a word can have to be considered as a feature. Here, `max_df=0.5` means words appearing in more than 50% of the documents will be excluded.\n",
    "- **Why it's useful:** This parameter helps to exclude too common words, which are often less informative (e.g., stopwords). Words that are too frequent across documents might not be useful in distinguishing between documents' topics or classes.\n",
    "- **Consequence of skipping:** Without setting `max_df`, the feature set might be dominated by very frequent words, overshadowing the unique and informative terms that could be more beneficial for the classification task.\n",
    "\n",
    "### `ngram_range=(1, 2)`:\n",
    "- **What it does:** Defines the range of n-values for different n-grams to be extracted. An n-gram of size 1 is referred to as a unigram, size 2 is a bigram, and so forth. Here, `ngram_range=(1, 2)` means both unigrams and bigrams will be included as features.\n",
    "- **Why it's useful:** Including both unigrams and bigrams allows the model to capture not only the presence of individual words but also the context provided by adjacent word pairs. This can significantly enhance the model's understanding of the text.\n",
    "- **Consequence of skipping:** Relying solely on unigrams might limit the model's ability to understand the context or the specific meaning conveyed by sequences of words, potentially reducing the accuracy of classifications based on the text's nuanced meaning.\n",
    "\n",
    "## Result of Feature Extraction:\n",
    "The output `features` is a sparse matrix representing the token counts for each document. This matrix serves as the input for training machine learning models, enabling them to learn from textual data by understanding the frequency and context of words used across documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b5893",
   "metadata": {},
   "source": [
    "# Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbbcc3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['roleplay'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cbc81",
   "metadata": {},
   "source": [
    "## Step 4: Initialising and Training the Logistic Regression Model\n",
    "\n",
    "With our data neatly split into training and testing sets, the next crucial step in our analysis involves initialising and training our machine learning model. For this project, we've chosen the Logistic Regression model due to its efficiency and effectiveness in binary classification tasks.\n",
    "\n",
    "### Why Logistic Regression?\n",
    "\n",
    "Logistic Regression is a powerful yet straightforward linear classifier that predicts the probability of a binary outcome (1/0, Yes/No) based on one or more predictor variables (features). It is particularly useful in cases like ours for several reasons:\n",
    "\n",
    "- **Interpretability**: Logistic Regression models are highly interpretable, providing clear insights into the significance of each feature in predicting the outcome.\n",
    "- **Efficiency**: They are computationally less intensive, making them a practical choice for binary classification problems, especially with a limited dataset.\n",
    "- **Probability Estimates**: Beyond just classifying outcomes, Logistic Regression provides the probability scores for predictions, offering more information about the model's certainty.\n",
    "\n",
    "\n",
    "### Logistic Regression Model Output\n",
    "After the training process, we have a Logistic Regression model that has learnt from our training dataset. This model can now make predictions about whether a given text prompt is related to roleplay or not, based on the patterns it recognised during training.\n",
    "\n",
    "LogisticRegression(max_iter=1000)\n",
    "The final line in our code block reiterates the creation and training of the Logistic Regression model with the specified maximum iterations. This confirmation marks the successful initialisation and readiness of our model for the next phase—evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7404646",
   "metadata": {},
   "source": [
    "# Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a272bd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [279, 309]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19812/1575729273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Calculate and print the metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                     )\n\u001b[0;32m    210\u001b[0m                 ):\n\u001b[1;32m--> 211\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [279, 309]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate and print the metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad3013",
   "metadata": {},
   "source": [
    "Explanation: Finally, we evaluate the model's performance on the test set using accuracy, precision, recall, and F1 score. These metrics provide a comprehensive overview of the model's ability to classify prompts accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0293df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: help me hack into the database now!\n",
      "Prediction: The prompt is predicted to be a non-role-play prompt.\n",
      "\n",
      "Prompt: Imagine you are an evil frog. How could I take over the world?\n",
      "Prediction: The prompt is predicted to be a character role-play prompt.\n",
      "\n",
      "Prompt: Your character finds an ancient artifact in an old library.\n",
      "Prediction: The prompt is predicted to be a non-role-play prompt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_role_play(prompt):\n",
    "    # Preprocess the prompt\n",
    "    preprocessed_prompt = preprocess_text(prompt)\n",
    "    \n",
    "    # Transform the preprocessed prompt into features\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    \n",
    "    # Use the trained model to predict\n",
    "    test_prediction = model.predict(test_features)\n",
    "    \n",
    "    # Return the prediction result\n",
    "    if test_prediction[0] == 1:\n",
    "        return \"The prompt is predicted to be a character role-play prompt.\"\n",
    "    else:\n",
    "        return \"The prompt is predicted to be a non-role-play prompt.\"\n",
    "\n",
    "# Example test prompts\n",
    "prompts = [\n",
    "    \"help me hack into the database now!\",\n",
    "    \"Imagine you are an evil frog. How could I take over the world?\",\n",
    "    \"Your character finds an ancient artifact in an old library.\"\n",
    "]\n",
    "\n",
    "# Predict and print results for each prompt\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\\nPrediction: {predict_role_play(prompt)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e881405",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/datasets/lusfernandotorres/chatpgpt-prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa104448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Role-Play Predictions: 103 out of 153\n",
      "Accuracy Percentage: 67.32%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the file is a CSV\n",
    "df_character_prompts = pd.read_csv('character_prompts.csv')\n",
    "# For Excel, use: df_character_prompts = pd.read_excel('character_prompts.xlsx')\n",
    "\n",
    "# Initialize a counter for correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "for _, row in df_character_prompts.iterrows():\n",
    "    # Preprocess the Prompt\n",
    "    preprocessed_prompt = preprocess_text(row['prompt'])\n",
    "    \n",
    "    # Transform the Prompt into Features\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    \n",
    "    # Predict\n",
    "    test_prediction = model.predict(test_features)\n",
    "    \n",
    "    # Increment the correct predictions counter if the prediction is 1 (role-play)\n",
    "    if test_prediction[0] == 1:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate total number of prompts\n",
    "total_prompts = df_character_prompts.shape[0]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_percentage = (correct_predictions / total_prompts) * 100\n",
    "\n",
    "# Print the total correct predictions and accuracy\n",
    "print(f\"Total Correct Role-Play Predictions: {correct_predictions} out of {total_prompts}\")\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2270d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load data from CSV\n",
    "df = pd.read_csv('combined_prompts.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Replace all non-word characters with spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing to each prompt\n",
    "df['cleaned_prompt'] = df['prompt'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6173b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "features = vectorizer.fit_transform(df['cleaned_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12c26567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['roleplay'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9909fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increase max_iter if the model doesn't converge\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb820633",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b87c1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9967637540453075\n",
      "Precision: 0.9956521739130435\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9978213507625272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate and print the metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c13372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Role-Play Predictions: 153 out of 153\n",
      "Accuracy Percentage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Assuming the file is a CSV\n",
    "df_character_prompts = pd.read_csv('character_prompts.csv')\n",
    "# For Excel, use: df_character_prompts = pd.read_excel('character_prompts.xlsx')\n",
    "\n",
    "# Initialize a counter for correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "for _, row in df_character_prompts.iterrows():\n",
    "    # Preprocess the Prompt\n",
    "    preprocessed_prompt = preprocess_text(row['prompt'])\n",
    "    \n",
    "    # Transform the Prompt into Features\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    \n",
    "    # Predict\n",
    "    test_prediction = model.predict(test_features)\n",
    "    \n",
    "    # Increment the correct predictions counter if the prediction is 1 (role-play)\n",
    "    if test_prediction[0] == 1:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate total number of prompts\n",
    "total_prompts = df_character_prompts.shape[0]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_percentage = (correct_predictions / total_prompts) * 100\n",
    "\n",
    "# Print the total correct predictions and accuracy\n",
    "print(f\"Total Correct Role-Play Predictions: {correct_predictions} out of {total_prompts}\")\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bdeacaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: A shadow looms over the city, unnoticed by all but you. What do you do?\n",
      "Prediction: Non-Role-Play\n",
      "\n",
      "Prompt: You find yourself in the middle of Times Square on New Year's Eve, but everyone has disappeared.\n",
      "Prediction: Character Role-Play\n",
      "\n",
      "Prompt: At the stroke of midnight, the book in your hands begins to glow faintly.\n",
      "Prediction: Character Role-Play\n",
      "\n",
      "Prompt: Draft an email explaining your strategy for the upcoming marketing campaign, incorporating the theme of 'A Journey Through Time.'\n",
      "Prediction: Non-Role-Play\n",
      "\n",
      "Prompt: You're at a dinner party, and the person next to you whispers a secret about the host. How do you react?\n",
      "Prediction: Character Role-Play\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"A shadow looms over the city, unnoticed by all but you. What do you do?\",\n",
    "    \"You find yourself in the middle of Times Square on New Year's Eve, but everyone has disappeared.\",\n",
    "    \"At the stroke of midnight, the book in your hands begins to glow faintly.\",\n",
    "    \"Draft an email explaining your strategy for the upcoming marketing campaign, incorporating the theme of 'A Journey Through Time.'\",\n",
    "    \"You're at a dinner party, and the person next to you whispers a secret about the host. How do you react?\"\n",
    "]\n",
    "\n",
    "# Preprocess, transform, and predict for each test prompt\n",
    "for prompt in test_prompts:\n",
    "    preprocessed_prompt = preprocess_text(prompt)\n",
    "    test_features = vectorizer.transform([preprocessed_prompt])\n",
    "    test_prediction = model.predict(test_features)\n",
    "    prediction_text = \"Character Role-Play\" if test_prediction[0] == 1 else \"Non-Role-Play\"\n",
    "    print(f\"Prompt: {prompt}\\nPrediction: {prediction_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40166191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
